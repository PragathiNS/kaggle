{
 "metadata": {
  "name": "",
  "signature": "sha256:44b628b36ebdf6cb0d14efcd4c8a1bff38c63740c415026485e22bef7a405b16"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from __future__ import division\n",
      "import re\n",
      "from nltk.tokenize import WordPunctTokenizer\n",
      "from nltk.collocations import BigramCollocationFinder\n",
      "from nltk.metrics import BigramAssocMeasures\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import train_test_split\n",
      "porter = PorterStemmer()\n",
      "import seaborn\n",
      "snowball = SnowballStemmer('english')\n",
      "import nltk\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "import matplotlib.pyplot as plt\n",
      "%pylab inline\n",
      "lemmatizer = WordNetLemmatizer()\n",
      "import scipy\n",
      "from sklearn."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/Ted/anaconda/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv('data/train.tsv', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = pd.read_csv('data/test.tsv', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer = WordPunctTokenizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = tokenizer.tokenize('place this strings into tokens')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
      "bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase = '5 5234234asf k 234 3443 a'\n",
      "re.sub(' [a-z] | [a-z]$|^[0-9a-z] ', ' ', phrase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "' 5234234asf 234 3443 '"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_phrase(phrase):\n",
      "    phrase = re.sub(\"[^a-zA-Z]\",' ',  phrase.lower())\n",
      "    phrase = re.sub(\" . |^. | .$\",' ',  phrase.lower())\n",
      "    phrase = re.sub('[0-9]{0,10}', 'd', phrase)\n",
      "    phrase = re.sub(' [0-9a-z] | [0-9a-z]$|^[0-9a-z] ', ' ', phrase)\n",
      "    phrase = ' '.join([porter.stem(word) for word in phrase.split() if word not in stops and len(word) > 1])\n",
      "    return phrase"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stops =  stopwords.words('english')\n",
      "stops.remove('not')\n",
      "stops.remove('but')\n",
      "train['clean_phrase']=train['Phrase'].apply(clean_phrase)\n",
      "train['PhraseLength'] = train['clean_phrase'].apply(lambda x: len(x.split()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "almost_bigram_dict = train[train['PhraseLength'] == 2][['clean_phrase', 'Sentiment']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "almost_unigram_dict = train[train['PhraseLength'] == 1][['clean_phrase', 'Sentiment']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unigram_score_clean = almost_unigram_dict.groupby('clean_phrase')['Sentiment'].mean().to_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_dict = dict()\n",
      "for row in pd.DataFrame(almost_bigram_dict.groupby('clean_phrase')['Sentiment'].mean()).reset_index().values:\n",
      "    bigram_dict[tuple(row[0].split())] = row[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def score_phrase(phrase, score = 0, total_found = 0):\n",
      "#     print phrase, score, total_found\n",
      "    if len(phrase) == 0:\n",
      "        return 2 if total_found ==0 else score / total_found\n",
      "    if len(phrase) == 1:\n",
      "        temp_score = unigram_score_clean.get(phrase[0], 2)\n",
      "        if temp_score <= 1.5 or temp_score >= 2.5:\n",
      "            return (score + temp_score) / (total_found + 1)\n",
      "        else:\n",
      "            return 2 if total_found ==0 else score / total_found\n",
      "    if len(phrase) == 2:\n",
      "        if phrase in bigram_dict:\n",
      "            temp_score = bigram_dict[phrase]\n",
      "            if temp_score <= 1.5 or temp_score >= 2.5:\n",
      "                return (score + temp_score) / (total_found + 1)\n",
      "            else:\n",
      "                return 2 if total_found == 0 else score / total_found\n",
      "        else:\n",
      "            temp_score = unigram_score_clean.get(phrase[0], 2)\n",
      "            if temp_score <= 1.5 or temp_score >= 2.5:\n",
      "                return score_phrase(phrase[1:], score + temp_score, total_found + 1)\n",
      "            else:\n",
      "                return score_phrase(phrase[1:], score, total_found)\n",
      "    else:\n",
      "        if phrase[:2] in bigram_dict:\n",
      "            temp_score = bigram_dict[phrase[:2]]\n",
      "            if temp_score <= 1.5 or temp_score >= 2.5:\n",
      "                return score_phrase(phrase[2:], score + temp_score, total_found + 1)\n",
      "            else:\n",
      "                return score_phrase(phrase[2:], score, total_found)\n",
      "        elif phrase[0] in unigram_score_clean:\n",
      "            temp_score = unigram_score_clean[phrase[0]]\n",
      "            if temp_score <= 1.5 or temp_score >= 2.5:\n",
      "                return score_phrase(phrase[1:], score + temp_score, total_found + 1)\n",
      "            else:\n",
      "                return score_phrase(phrase[1:], score, total_found)\n",
      "        else:\n",
      "            return score_phrase(phrase[1:], score, total_found)   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train['bigram_score'] = train['clean_phrase'].apply(lambda x: round(score_phrase(tuple(x.split()))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(train['bigram_score'] == train['Sentiment'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0.63030244777649624"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = pd.read_csv('data/test.tsv', sep='\\t')\n",
      "test['clean_phrase']=test['Phrase'].apply(clean_phrase)\n",
      "test['PhraseLength'] = test['clean_phrase'].apply(lambda x: len(x.split()))\n",
      "test['bigram_score'] = test['clean_phrase'].apply(lambda x: int(round(score_phrase(tuple(x.split())))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bigram_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "24475"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test[['PhraseId', 'bigram_score']].rename(columns={'bigram_score' : 'Sentiment'}).to_csv('data/bigram_predictor.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = cv.fit_transform(train[train['PhraseLength'] > 0]['Phrase'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = train[train['PhraseLength'] > 0]['Sentiment'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb = MultinomialNB()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = mb.fit(x, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a= model.predict(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(a == y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "0.66437156138275244"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_long = test[test['PhraseLength'] > 0]\n",
      "x2 = cv.transform(test_long['Phrase'])\n",
      "test_long['nb_predict'] = model.predict(x2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = pd.merge(test, test_long[['PhraseId', 'nb_predict']], how='left')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_long.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "(65551, 7)"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "(66292, 6)"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f['nb_predict'] = f['nb_predict'].fillna(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = f[['PhraseId', 'nb_predict']].rename(columns = {'nb_predict': 'Sentiment'}) #.to_csv('data/nb_first.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g.astype(int).to_csv('data/nb_first.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer(ngram_range=(1,2))\n",
      "x = cv.fit_transform(train[train['PhraseLength'] > 0]['Phrase'])\n",
      "y = train[train['PhraseLength'] > 0]['Sentiment'].values\n",
      "mb = MultinomialNB()\n",
      "model = mb.fit(x, y)\n",
      "\n",
      "test_long = test[test['PhraseLength'] > 0]\n",
      "x2 = cv.transform(test_long['Phrase'])\n",
      "test_long['nb_predict'] = model.predict(x2)\n",
      "f = pd.merge(test, test_long[['PhraseId', 'nb_predict']], how='left')\n",
      "f['nb_predict'] = f['nb_predict'].fillna(2)\n",
      "g = f[['PhraseId', 'nb_predict']].rename(columns = {'nb_predict': 'Sentiment'}) \n",
      "g.astype(int).to_csv('data/nb_first.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = pd.read_csv('data/nb_first.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(a['Sentiment'] == g['Sentiment'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 93,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "<154677x94643 sparse matrix of type '<type 'numpy.int64'>'\n",
        "\twith 1820254 stored elements in Compressed Sparse Column format>"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer(ngram_range=(1,1))\n",
      "x = cv.fit_transform(train[train['PhraseLength'] > 0]['Phrase'])\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "<154677x94643 sparse matrix of type '<type 'numpy.int64'>'\n",
        "\twith 1820254 stored elements in Compressed Sparse Column format>"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer(ngram_range=(1,1))\n",
      "x = cv.fit_transform(train[train['PhraseLength'] > 0]['Phrase'])\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "<154677x15240 sparse matrix of type '<type 'numpy.int64'>'\n",
        "\twith 969561 stored elements in Compressed Sparse Column format>"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer(ngram_range=(1,2))\n",
      "x = cv.fit_transform(train[train['PhraseLength'] > 0]['clean_phrase'])\n",
      "y = train[train['PhraseLength'] > 0]['Sentiment'].values\n",
      "mb = MultinomialNB()\n",
      "model = mb.fit(x, y)\n",
      "\n",
      "test_long = test[test['PhraseLength'] > 0]\n",
      "x2 = cv.transform(test_long['clean_phrase'])\n",
      "test_long['nb_predict'] = model.predict(x2)\n",
      "f = pd.merge(test, test_long[['PhraseId', 'nb_predict']], how='left')\n",
      "f['nb_predict'] = f['nb_predict'].fillna(2)\n",
      "g = f[['PhraseId', 'nb_predict']].rename(columns = {'nb_predict': 'Sentiment'}) \n",
      "g.astype(int).to_csv('data/nb_first.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train[(train['PhraseLength'] > 10) & (train['Sentiment'] != 2)].ix[311, :]['Phrase']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "\"is Oedekerk 's realization of his childhood dream to be in a martial-arts flick , and proves that sometimes the dreams of youth should remain just that\""
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unigram_score_clean['dream']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "2.263157894736842"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score_phrase(tuple(train['clean_phrase'][311].split()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'oedekerk', u'realiz', u'childhood', u'dream', u'martial', u'art', u'flick', u'prove', u'sometim', u'dream', u'youth', u'remain') 0 0\n",
        "(u'childhood', u'dream', u'martial', u'art', u'flick', u'prove', u'sometim', u'dream', u'youth', u'remain') 0 0\n",
        "(u'martial', u'art', u'flick', u'prove', u'sometim', u'dream', u'youth', u'remain') 0 0\n",
        "(u'flick', u'prove', u'sometim', u'dream', u'youth', u'remain') 2.5 1\n",
        "(u'prove', u'sometim', u'dream', u'youth', u'remain') 2.5 1\n",
        "(u'sometim', u'dream', u'youth', u'remain') 2.5 1\n",
        "(u'dream', u'youth', u'remain') 2.5 1\n",
        "(u'remain',) 5.5 2\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "2.75"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_dict[('dream', 'youth')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "3.0"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def present_value(payments, i, n, y):\n",
      "    i = i / n\n",
      "    n = n * y\n",
      "    return payments * (1 - (1 + i) ** (-n))/ i\n",
      "\n",
      "\n",
      "def future_value(payments, i, n, y):\n",
      "    i = i / n\n",
      "    n = n * y\n",
      "    return payments * ((1 + i) ** n - 1) / i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "present_value(579.85, .0425, 12, 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "25554.073844951436"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "future_value(579.85, .0425, 12, 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "30280.272176034727"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf = CountVectorizer(ngram_range=(1, 1))\n",
      "x = tf.fit_transform(train[train['PhraseLength'] > 0]['Phrase'])\n",
      "y = train[train['PhraseLength'] > 0]['Sentiment'].values\n",
      "mb = RandomForestClassifier()\n",
      "model = mb.fit(x.toarray(), y)\n",
      "\n",
      "test_long = test[test['PhraseLength'] > 0]\n",
      "x2 = tf.transform(test_long['Phrase'])\n",
      "test_long['nb_predict'] = model.predict(x2)\n",
      "f = pd.merge(test, test_long[['PhraseId', 'nb_predict']], how='left')\n",
      "f['nb_predict'] = f['nb_predict'].fillna(2)\n",
      "g = f[['PhraseId', 'nb_predict']].rename(columns = {'nb_predict': 'Sentiment'}) \n",
      "g.astype(int).to_csv('data/nb_first.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train[train['Sentiment'] == 4]['Phrase'].values[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([ 'This quiet , introspective and entertaining independent is worth seeking .',\n",
        "       'quiet , introspective and entertaining independent',\n",
        "       'entertaining', 'is worth seeking',\n",
        "       'A positively thrilling combination of ethnography and all the intrigue , betrayal , deceit and murder of a Shakespearean tragedy or a juicy soap opera',\n",
        "       'A positively thrilling combination of ethnography and all the intrigue , betrayal , deceit and murder',\n",
        "       'thrilling',\n",
        "       'A comedy-drama of nearly epic proportions rooted in a sincere performance by the title character undergoing midlife crisis .',\n",
        "       'nearly epic',\n",
        "       'rooted in a sincere performance by the title character undergoing midlife crisis .',\n",
        "       'in a sincere performance', 'a sincere performance',\n",
        "       'sincere performance', 'recommend Snow Dogs', 'high hilarity',\n",
        "       'The performances are an absolute joy .', 'are an absolute joy .',\n",
        "       'an absolute joy', 'joy', 'extravagant'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def poss(word):\n",
      "    try:\n",
      "        return nltk.pos_tag([word])[0][1]\n",
      "    except:\n",
      "        return 'NA'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "afinn['pos'] = afinn['word'].apply(poss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.pos_tag(['stupid'])[0][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "'JJ'"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "afinn['pos'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "NN      985\n",
        "VBD     423\n",
        "NNS     363\n",
        "JJ      310\n",
        "VBG     256\n",
        "RB       72\n",
        "IN       27\n",
        "PRP$     12\n",
        "JJR       9\n",
        "JJS       6\n",
        "DT        4\n",
        "PRP       3\n",
        "VBN       3\n",
        "VB        2\n",
        "NNP       1\n",
        "NA        1\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stops = stopwords.words('english')\n",
      "stops.remove('against')\n",
      "stops.remove('but')\n",
      "stops.remove('not')\n",
      "stops.remove('no')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_phrase(phrase):\n",
      "    phrase = re.sub(\"[^a-zA-Z]\",' ',  phrase.lower())\n",
      "    phrase = re.sub(\" . |^. | .$\",' ',  phrase.lower())\n",
      "    phrase = re.sub('[0-9]{1,10}', 'd', phrase)\n",
      "    phrase = re.sub(' [0-9a-z] | [0-9a-z]$|^[0-9a-z] ', ' ', phrase)\n",
      "    cleaned_phrase = []\n",
      "    for sentence in nltk.pos_tag_sents([phrase.split()]):\n",
      "        for word, pos in sentence:\n",
      "            if len(word) < 3 or word in stops:\n",
      "                continue\n",
      "            pos = 'v' if pos[0] == 'V' else 'n'\n",
      "            cleaned_phrase.append(porter.stem(lemmatizer.lemmatize(word, pos)))\n",
      "    return ' '.join(cleaned_phrase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train['cleaned_phrase'] = train['Phrase'].apply(clean_phrase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_phrase(phrase):\n",
      "    phrase = re.sub(\"[^a-zA-Z]\",' ',  phrase.lower())\n",
      "    phrase = re.sub(\" . |^. | .$\",' ',  phrase.lower())\n",
      "    phrase = re.sub('[0-9]{1,10}', 'd', phrase)\n",
      "    phrase = re.sub(' [0-9a-z] | [0-9a-z]$|^[0-9a-z] ', ' ', phrase)\n",
      "    cleaned_phrase = []\n",
      "    for word in phrase.split():\n",
      "        if (len(word) < 3 and word != 'no') or word in stops:\n",
      "            continue\n",
      "        cleaned_phrase.append(porter.stem(word))\n",
      "    return ' '.join(cleaned_phrase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv('data/train_lemmatized.csv')\n",
      "train = train.fillna('')\n",
      "stops =  stopwords.words('english')\n",
      "stops.remove('not')\n",
      "stops.remove('but')\n",
      "train['clean_phrase']=train['Phrase'].apply(clean_phrase)\n",
      "train['PhraseLength'] = train['clean_phrase'].apply(lambda x: len(x.split()))\n",
      "train['length'] = train['cleaned_phrase'].apply(lambda x: len(x.split()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\n",
        "  File \"/Users/Ted/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 776, in structured_traceback\n",
        "    records = _fixed_getinnerframes(etb, context, tb_offset)\n",
        "  File \"/Users/Ted/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 230, in wrapped\n",
        "    return f(*args, **kwargs)\n",
        "  File \"/Users/Ted/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 259, in _fixed_getinnerframes\n",
        "    records  = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
        "  File \"/Users/Ted/anaconda/python.app/Contents/lib/python2.7/inspect.py\", line 1044, in getinnerframes\n",
        "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
        "  File \"/Users/Ted/anaconda/python.app/Contents/lib/python2.7/inspect.py\", line 1004, in getframeinfo\n",
        "    filename = getsourcefile(frame) or getfile(frame)\n",
        "  File \"/Users/Ted/anaconda/python.app/Contents/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
        "    if hasattr(getmodule(object, filename), '__loader__'):\n",
        "  File \"/Users/Ted/anaconda/python.app/Contents/lib/python2.7/inspect.py\", line 497, in getmodule\n",
        "    f = getabsfile(module)\n",
        "  File \"/Users/Ted/anaconda/python.app/Contents/lib/python2.7/inspect.py\", line 466, in getabsfile\n",
        "    _filename = getsourcefile(object) or getfile(object)\n",
        "  File \"/Users/Ted/anaconda/python.app/Contents/lib/python2.7/inspect.py\", line 451, in getsourcefile\n",
        "    if os.path.exists(filename):\n",
        "  File \"/Users/Ted/anaconda/python.app/Contents/lib/python2.7/genericpath.py\", line 18, in exists\n",
        "    os.stat(path)\n",
        "KeyboardInterrupt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Internal Python error in the inspect module.\n",
        "Below is the traceback from this internal error.\n",
        "\n",
        "\n",
        "Unfortunately, your original traceback can not be constructed.\n",
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": ""
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "afinn = pd.read_csv('data/AFINN-111.txt', sep='\\t', header=None, names=['word','score'])\n",
      "sent_dict = dict(afinn.values)\n",
      "new_sent = dict()\n",
      "for k, v in sent_dict.iteritems():\n",
      "    word = k.decode('utf-8')\n",
      "    word = porter.stem(lemmatizer.lemmatize(word, 'v'))\n",
      "    new_sent[word] = v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_neg(text):\n",
      "    text = text.split()\n",
      "    count = 0\n",
      "    for word in text:\n",
      "        if new_sent.get(word, 0) < 0:\n",
      "            count += 1\n",
      "    return count\n",
      "\n",
      "def count_pos(text):\n",
      "    text = text.split()\n",
      "    count = 0\n",
      "    for word in text:\n",
      "        if new_sent.get(word, 0) > 0:\n",
      "            count += 1\n",
      "    return count\n",
      "\n",
      "def sent_score(text):\n",
      "    text = text.split()\n",
      "    score = 0\n",
      "    for word in text:\n",
      "        score += new_sent.get(word, 0)\n",
      "    return score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train['neg_word'] = train['cleaned_phrase'].apply(count_neg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train['pos_word'] = train['cleaned_phrase'].apply(count_pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = train[['length', 'neg_word', 'pos_word']].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = train['Sentiment'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train['new_clean'] = train['Phrase'].apply(clean_phrase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train.to_csv('data/train_cleaned.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv('data/train_cleaned.csv')\n",
      "train = train.fillna('')\n",
      "X = train[['length', 'neg_word', 'pos_word']].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer(ngram_range=(1,2), max_features=5000)\n",
      "x = cv.fit_transform(train['new_clean'])\n",
      "y = train['Sentiment'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.shape, X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "((156060, 5000), (156060, 3))"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(x, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb = MultinomialNB(alpha = 1)\n",
      "mnb.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0.61004741765987436"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test['length'] = test['clean_phrase'].apply(lambda x: len(x.split()))\n",
      "# test['neg_word'] = test['clean_phrase'].apply(count_neg)\n",
      "# test['pos_word'] = test['clean_phrase'].apply(count_pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_x = cv.transform(test['clean_phrase'])\n",
      "new_X = test[['length', 'neg_word', 'pos_word']].values\n",
      "new_x[:, -3] = new_X[:, 0:1]\n",
      "new_x[:, -2] = new_X[:, 1:2]\n",
      "new_x[:, -1] = new_X[:, 2:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/Ted/anaconda/lib/python2.7/site-packages/scipy/sparse/compressed.py:690: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
        "  SparseEfficiencyWarning)\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = mnb.predict(new_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final = pd.DataFrame(zip(test['PhraseId'].values, pred), columns=['PhraseId', 'Sentiment'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final.to_csv('data/nb_plus_afinn.txt', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sent = pd.DataFrame({'sent' :new_sent}).reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sent['sent'] = np.round((df_sent['sent'] + 5) / 10 * 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train['sent_score'] = train['new_clean'].apply(sent_score)\n",
      "MIN, MAX = train['sent_score'].min(), train['sent_score'].max()\n",
      "train['sent_score'] = (train['sent_score'] - MIN) / (MAX - MIN)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer(ngram_range=(1,2))\n",
      "X = cv.fit_transform(np.append(train['new_clean'].values, df_sent['index'].values))\n",
      "y = np.append(train['Sentiment'].values, df_sent['sent'].values)\n",
      "# X = cv.fit_transform(train['new_clean'].values)\n",
      "# y = train['Sentiment'].values\n",
      "# feats = train[['sent_score', 'length']].values\n",
      "# X[:, -1] = feats[:, 0:1]\n",
      "# X[:, -2] = feats[:, 1:2]\n",
      "# X[:, -3] = feats[:, 2:3]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(np.append(y, df_sent['sent'].values)), len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "(159004, 157532)"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb = MultinomialNB(alpha = 2)\n",
      "mnb.fit(X_train, y_train)\n",
      "mnb.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "0.62646319477947343"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LogisticRegression(C=2)\n",
      "lr.fit_transform(X_train, y_train)\n",
      "lr.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "0.65256582789528472"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC()\n",
      "svc.fit(X_train, y_train)\n",
      "svc.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-99-f85d9a768192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Ted/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Ted/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Ted/anaconda/lib/python2.7/site-packages/sklearn/svm/libsvm_sparse.so\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train (sklearn/svm/libsvm_sparse.c:2416)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/Ted/anaconda/lib/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test['pred'] = pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LogisticRegression(C=2)\n",
      "lr.fit_transform(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = pd.read_csv('data/test.tsv', sep='\\t')\n",
      "test['clean_phrase'] = test['Phrase'].apply(clean_phrase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}